\chapter*{Abstract}

Datacenters serve as the foundational infrastructure for modern computing.
However, workloads' escalating demands for resources have necessitated for ever
larger and more complex datacenters. Datacenter schedulers must allocate these
diverse resources across an increasing volume of dynamic workloads to achieve
set performance objects, with any small variations incurring considerable
operational costs. This has incentivised research into this field, with numerous
architectures and algorithms having been proposed. \textsc{Pronto} was proposed
to tackle the existing trade-off when predicting the availability of node
resources: responsiveness vs. a more holistic view of the entire datacenter.
\textsc{Pronto} exploits federated learning (FL) techniques to distribute
knowledge aggregation and processing across all the compute nodes in a
datacenter in an online and memory-limited manner. \textsc{Pronto} showed that
nodes with a global model of the datacenter could more accurately predict the
availability of their resources.

With the wide-spread adoption of containerized workloads in datacenters,
Kubernetes, an open-source container orchestration system, has established
itself as cornerstone of the cloud-native industry. Consequently, efficient
scheduling is paramount. The Kubernetes default scheduler
(\texttt{kube-scheduler}) relies on accurate user-provided container resource
requests. To improve the quality of resource requests, telemetric-based
schedulers have been proposed, but either use expensive machine learning
techniques or focus on a per-Node level.

\textsc{Pronto} ability to efficiently aggregate telemetry across a datacenter
in an online fashion offers a promising direction. However, \textsc{Pronto}'s
no communication latency assumption, its binary signal, and Kubernetes' noisy
environment make its algorithm difficult to apply to a Kubernetes setting.
Consequently, I propose \textsc{Carico} (Italian for "load"), a novel federated,
asynchronous and memory-limited scheduler that shares \textsc{Pronto}'s core
properties but accounts for communication latency. Nodes perform Federated
Singular Value Decomposition (FSVD) on capacity-based metrics, modeling past
resource usage across the datacenter to estimate future workload capacity. This
capacity is advertised as a continuous comparable signal which can be reserved
to account for Pod start-up delay.

To evaluate \textsc{Carico}, I implemented a prototype within the Kubernetes ecosystem.
This involved extensive investigation into various metrics and filters to
generate an accurate model of recent workloads and a Node's corresponding
capacity signal. Finally, I benchmarked \textsc{Carico}'s overall performance
against the \texttt{kube-scheduler} on a Kubernetes cluster with diverse
workloads. While \textsc{Carico} achieved comparable Job Completion times, it
significantly outperformed \texttt{kube-scheduler} as a QoS scheduler,
demonstrating lower Pod Completion times and improved workload isolation.
