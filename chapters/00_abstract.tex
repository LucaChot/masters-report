\chapter*{Abstract}

Kubernetes is a widely-used open-source container orchestration system
that automates the deployment, scaling and management of containerized
applications. Efficient scheduling is a critical component of Kubernetes,
dictating an optimal allocation of pods across nodes to maximise a set of goals.
Kubernetes schedulers generally fall into two categories: pod-descriptive and
telemetric-based. Pod-descriptive schedulers, like the default
\texttt{kube-scheduler}, rely on accurately defined Pod resource requests for
optimal performance. In contrast, telemetric-based schedulers leverage collected
Node metrics to identify under or over-utilized Nodes. While these are often
used to refine decisions made by existing pod-descriptive schedulers, this
dissertation focuses on exploring the potential of a telemetric-only scheduler.

Scheduling in Kubernetes without explicit Pod resource requests remains largely
unexplored due to its complexity. Traditional bin-packing approaches are
insufficient; instead, a telemetric-only scheduler requires a novel strategy to
derive optimal plans from collected telemetry.

\textsc{Pronto} offers a promising direction. This federated, asynchronous, and
memory-limited algorithm schedules tasks across hundreds of workers. It enables
individual workers to build local workload models from telemetry, which are then
aggregated to form a global system view. For a telemetric-only scheduler,
maximizing information aggregation is crucial. However, in very large clusters,
centralizing all this data quickly becomes a bottleneck. By distributing the
knowledge federation workload across the cluster, we can significantly reduce
the load on a central scheduler.

Unfortunately, \textsc{Pronto}'s direct application to Kubernetes proved unfeasible due
to its communication latency assumptions and early empirical findings.
Consequently, I propose \textsc{Carico} (Italian for "load"), a novel scheduler that
shares \textsc{Pronto}'s core properties but accounts for communication latency. \textsc{Carico}
enables Nodes to perform Federated Singular Value Decomposition (FSVD) on
capacity-based metrics, modeling past resource usage to estimate future
workload capacity.

To evaluate \textsc{Carico}, I implemented a prototype within the Kubernetes ecosystem.
This involved extensive investigation into various metrics and filters to
generate a precise capacity signal. Finally, I benchmarked \textsc{Carico}'s overall
performance against the default kube-scheduler on a Kubernetes cluster with
diverse workloads. While \textsc{Carico} achieved comparable throughput, it significantly
outperformed kube-scheduler as a QoS scheduler, demonstrating lower Pod
Completion times and improved workload isolation.
