@misc{pruhs2004online,
  title={Online scheduling.},
  author={Pruhs, Kirk and Sgall, Jiri and Torng, Eric},
  year={2004}
}

@article{hadoop2016apache,
  title={Apache hadoop yarn},
  author={Hadoop, Apache},
  journal={The Apache Software Foundation},
  year={2016}
}

--------------------------------------------------------------------------------

@article{jian_drs_2024,
	title = {{DRS}: {A} deep reinforcement learning enhanced {Kubernetes} scheduler for microservice-based system},
	volume = {54},
	issn = {1097-024X},
	shorttitle = {{DRS}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.3284},
	doi = {10.1002/spe.3284},
	abstract = {Recently, Kubernetes is widely used to manage and schedule the resources of microservices in cloud-native distributed applications, as the most famous container orchestration framework. However, Kubernetes preferentially schedules microservices to nodes with rich and balanced CPU and memory resources on a single node. The native scheduler of Kubernetes, called Kube-scheduler, may cause resource fragmentation and decrease resource utilization. In this paper, we propose a deep reinforcement learning enhanced Kubernetes scheduler named DRS. We initially frame the Kubernetes scheduling problem as a Markov decision process with intricately designed state, action, and reward structures in an effort to increase resource usage and decrease load imbalance. Then, we design and implement DRS mointor to perceive six parameters concerning resource utilization and create a thorough picture of all available resources globally. Finally, DRS can automatically learn the scheduling policy through interaction with the Kubernetes cluster, without relying on expert knowledge about workload and cluster status. We implement a prototype of DRS in a Kubernetes cluster with five nodes and evaluate its performance. Experimental results highlight that DRS overcomes the shortcomings of Kube-scheduler and achieves the expected scheduling target with three workloads. With only 3.27\% CPU overhead and 0.648\% communication delay, DRS outperforms Kube-scheduler by 27.29\% in terms of resource utilization and reduces load imbalance by 2.90 times on average.},
	language = {en},
	number = {10},
	urldate = {2025-05-02},
	journal = {Software: Practice and Experience},
	author = {Jian, Zhaolong and Xie, Xueshuo and Fang, Yaozheng and Jiang, Yibing and Lu, Ye and Dash, Ankan and Li, Tao and Wang, Guiling},
	year = {2024},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.3284},
	keywords = {deep reinforcement learning, Kubernetes scheduler, microservice scheduling, resource awareness},
	pages = {2102--2126},
	file = {Full Text PDF:/Users/luca/Zotero/storage/XP7JP3R7/Jian et al. - 2024 - DRS A deep reinforcement learning enhanced Kubernetes scheduler for microservice-based system.pdf:application/pdf},
}

@article{rakrouki_qos-aware_2022,
	title = {{QoS}-{Aware} {Algorithm} {Based} on {Task} {Flow} {Scheduling} in {Cloud} {Computing} {Environment}},
	volume = {22},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/22/7/2632},
	doi = {10.3390/s22072632},
	abstract = {This paper deals with the challenging problem of scheduling users’ tasks, while taking into consideration users’ quality of service (QoS) requirements, with the objective of reducing the energy consumption of physical machines. This paper presents a model to analyze the current state of the running tasks according to the results of the QoS prediction assigned by an ARIMA prediction model optimized with Kalman ﬁlter. Then, we calculate a scheduling policy with a combined particle swarm optimization (PSO) and gravitational search algorithm (GSA) algorithms according to the QoS status analysis. Experimental results show that the proposed HPSO algorithm reduces resources consumption 16.51\% more than the original hybrid algorithm, and the violation of service-level agreement (SLA) is 0.053\% less when the optimized prediction model is used.},
	language = {en},
	number = {7},
	urldate = {2025-05-02},
	journal = {Sensors},
	author = {Rakrouki, Mohamed Ali and Alharbe, Nawaf},
	month = mar,
	year = {2022},
	pages = {2632},
	file = {PDF:/Users/luca/Zotero/storage/KXJIXBLC/Rakrouki and Alharbe - 2022 - QoS-Aware Algorithm Based on Task Flow Scheduling in Cloud Computing Environment.pdf:application/pdf},
}

@misc{grammenos_pronto_2021,
	title = {Pronto: {Federated} {Task} {Scheduling}},
	shorttitle = {Pronto},
	url = {http://arxiv.org/abs/2104.13429},
	doi = {10.48550/arXiv.2104.13429},
	abstract = {We present a federated, asynchronous, memory-limited algorithm for online task scheduling across large-scale networks of hundreds of workers. This is achieved through recent advancements in federated edge computing that unlocks the ability to incrementally compute local model updates within each node separately. This local model is then used along with incoming data to generate a rejection signal which reflects the overall node responsiveness and if it is able to accept an incoming task without resulting in degraded performance. Through this innovation, we allow each node to execute scheduling decisions on whether to accept an incoming job independently based on the workload seen thus far. Further, using the aggregate of the iterates a global view of the system can be constructed, as needed, and could be used to produce a holistic perspective of the system. We complement our findings, by an empirical evaluation on a large-scale real-world dataset of traces from a virtualized production data center that shows, while using limited memory, that our algorithm exhibits state-of-the-art performance. Concretely, it is able to predict changes in the system responsiveness ahead of time based on the industry-standard CPU-Ready metric and, in turn, can lead to better scheduling decisions and overall utilization of the available resources. Finally, in the absence of communication latency, it exhibits attractive horizontal scalability.},
	urldate = {2025-05-14},
	publisher = {arXiv},
	author = {Grammenos, Andreas and Kalyvianaki, Evangelia and Pietzuch, Peter},
	month = apr,
	year = {2021},
	note = {arXiv:2104.13429 [cs]},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {Full Text PDF:/Users/luca/Zotero/storage/XN2P7564/Grammenos et al. - 2021 - Pronto Federated Task Scheduling.pdf:application/pdf;Snapshot:/Users/luca/Zotero/storage/5PG2V5EZ/2104.html:text/html},
}

@incollection{singh_airflow_2019,
	address = {Berkeley, CA},
	title = {Airflow},
	isbn = {978-1-4842-4961-1},
	url = {https://doi.org/10.1007/978-1-4842-4961-1_4},
	abstract = {This chapter focuses on introducing Airflow and how it can be used to handle complex data workflows. Airflow was developed in-house by Airbnb engineers, to manage internal workflows in an efficient manner. Airflow later went on to become part of Apache in 2016 and was made available to users as an open source. Basically, Airflow is a framework for executing, scheduling, distributing, and monitoring various jobs in which there can be multiple tasks that are either interdependent or independent of one another. Every job that is run using Airflow must be defined via a directed acyclic graph (DAG) definition file, which contains a collection you want to run, grouped by relationships and dependencies.},
	language = {en},
	urldate = {2025-05-14},
	booktitle = {Learn {PySpark}: {Build} {Python}-based {Machine} {Learning} and {Deep} {Learning} {Models}},
	publisher = {Apress},
	author = {Singh, Pramod},
	editor = {Singh, Pramod},
	year = {2019},
	doi = {10.1007/978-1-4842-4961-1_4},
	pages = {67--84},
}

@misc{kube-page,
	title = {Overview},
	url = {https://kubernetes.io/docs/concepts/overview/},
	abstract = {Kubernetes is a portable, extensible, open source platform for managing containerized workloads and services, that facilitates both declarative configuration and automation. It has a large, rapidly growing ecosystem. Kubernetes services, support, and tools are widely available.},
	language = {en},
	urldate = {2025-05-15},
	journal = {Kubernetes},
	file = {Snapshot:/Users/luca/Zotero/storage/94NXUH6C/overview.html:text/html},
}

@misc{qadeer_scaling_2022,
	title = {Scaling {Kubernetes} to {Over} 4k {Nodes} and 200k {Pods}},
	url = {https://medium.com/paypal-tech/scaling-kubernetes-to-over-4k-nodes-and-200k-pods-29988fad6ed},
	abstract = {Kubernetes’ scalability is not limited to the number of nodes \& pods. Learn how PayPal solved the challenges of scaling Kubernetes…},
	language = {en},
	urldate = {2025-05-15},
	journal = {The PayPal Technology Blog},
	author = {Qadeer, Abdul},
	month = jan,
	year = {2022},
	file = {Snapshot:/Users/luca/Zotero/storage/JURNVK5R/scaling-kubernetes-to-over-4k-nodes-and-200k-pods-29988fad6ed.html:text/html},
}

@inproceedings{sahasrabudhe_improved_2015,
    title = {Improved filter-weight algorithm for utilization-aware resource scheduling in {OpenStack}},
    url = {https://ieeexplore.ieee.org/document/7489348/},
    doi = {10.1109/INFOP.2015.7489348},
    abstract = {OpenStack is a cloud computing platform. OpenStack provides an Infrastructure as a Service (IaaS). OpenStack constitutes resources such as compute, storage and network resources. Resource allocation in cloud environment deals with assigning available resources in cost effective manner. Compute resources are allocated in the form of virtual machines (aka instances). Storage resources are allocated in the form of virtual disks (aka volumes). Network resources are allocated in the form of virtual switches, routers and subnets for instance. Resource allocation in OpenStack is carried out by nova-scheduler. However, it is unable to support providers objectives such as allocation of resources based on user privileges, preference to underlying physical infrastructure, actual resource utilizations for example, CPU, memory, storage, network bandwidth etc. An improved nova-scheduler algorithm considers not only RAM, CPU but also vCPU utilization and network bandwidth. Improved nova-scheduler is referred as metrics-weight scheduler in this paper. This paper gives performance evaluation and analysis of Filter-scheduler and Metrics-weight scheduler.},
    urldate = {2025-05-15},
    booktitle = {2015 {International} {Conference} on {Information} {Processing} ({ICIP})},
    author = {Sahasrabudhe, Shalmali and Sonawani, Shilpa S.},
    month = dec,
    year = {2015},
    keywords = {Cloud computing, filtering, Filtering algorithms, Information filters, multi-objective, nova-scheduler, OpenStack, Resource Allocation, Resource management, Servers, Virtual machining, weighting},
    pages = {43--47},
    file = {Full Text PDF:/Users/luca/Zotero/storage/DBBI6CHC/Sahasrabudhe and Sonawani - 2015 - Improved filter-weight algorithm for utilization-aware resource scheduling in OpenStack.pdf:application/pdf},
}

@misc{proc_stat5,
    title = {proc\_stat(5) - {Linux} manual page},
    url = {https://www.man7.org/linux/man-pages/man5/proc_stat.5.html},
    urldate = {2025-05-15},
    file = {proc_stat(5) - Linux manual page:/Users/luca/Zotero/storage/IQGL6NWX/proc_stat.5.html:text/html},
}
